{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ea3a2ed-2e52-4f6c-b58d-206bfe18b72e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e814cb8-7faf-4bc7-9afc-e4a8db39a761",
   "metadata": {},
   "source": [
    "## dot product attention(Luong attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115f9c7-f1bf-4576-ba14-39ad2aab6e4b",
   "metadata": {},
   "source": [
    "----\n",
    "input embedding : Nx1이라고 가정 \n",
    "hidden state : 5x1 이라고 가정   \n",
    "$H = [h_1,h_2,\\cdots , h_{N-1},h_N]$\n",
    "$H\\in \\mathbb{R}^{5xN} , s^t \\in \\mathbb{R}^{5x1}$  \n",
    "\\begin{align*}\n",
    "e^t &= H^Ts_t  \\\\\n",
    "    &= [h_1^T s_t,h_2^Ts_t,\\cdots , h_{N-1}^Ts_t,h_N^Ts_t]^T \\\\\n",
    "    &= [s_t^Th_1 ,s_t^Th_2,\\cdots , s_t^Th_{N-1},s_t^Th_N]\\\\\n",
    "\\\\\n",
    "\\\\e^t \\in \\mathbb{R}^N\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "\\alpha_t = softmax(e^t)  \\qquad \\alpha_t \\in \\mathbb{R}^N $ : \\text{attention distribution}\\\\\n",
    "a_t &= \\sum_{i=1}^N \\alpha_t^i h_i\\\\\n",
    "    &=H\\alpha_t\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b7fbc-6b94-49c5-a6aa-67b06a1693b3",
   "metadata": {},
   "source": [
    "$H\\alpha_t \\in \\mathbb{R}^5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be868015-2b36-436e-8058-5093db17f7ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1]), torch.Size([10, 5]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N = 10이라고 가정 , 10개의 token이 존재하는 것 \n",
    "st = torch.randn(5,1,dtype=torch.float32) # \n",
    "H = torch.randn(5,10)\n",
    "# H  = torch.randint(1,10,(5,10),dtype = torch.float32)\n",
    "st.shape, H.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb3bfaca-5ea3-4aae-9c53-a8696f8ec3c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et = torch.matmul(H.T,st) # attention score\n",
    "et.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "266f8d64-adc1-495a-a224-23fcc0272bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0195],\n",
       "         [0.0350],\n",
       "         [0.6956],\n",
       "         [0.0208],\n",
       "         [0.0302],\n",
       "         [0.0035],\n",
       "         [0.0952],\n",
       "         [0.0506],\n",
       "         [0.0347],\n",
       "         [0.0148]]),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = nn.Softmax(dim=0)(et)\n",
    "alpha, alpha.shape #attention distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46303aa1-489a-41ba-8f4b-50ba0b878404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_vector = torch.matmul(H,alpha) # attention in value process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59da7cd8-3525-4849-b91e-3fd417eecede",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1]), torch.Size([5, 1]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector.shape,st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bed48253-954c-4585-bbcd-01bf796cfb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt = torch.vstack((st,context_vector))\n",
    "vt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0580ab73-fdb0-4e04-90f3-b3b032c3c7f5",
   "metadata": {},
   "source": [
    "# Bahdanau Attention (바다나우 어텐션)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca1fc6e9-4df5-49eb-87bb-a40973721e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1]), torch.Size([5, 10]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_t1 = torch.randn_like(st)\n",
    "s_t1.shape, H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6a84b-f855-435c-a8a0-501d46f63c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q, K \n",
    "\n",
    "# nn.Linear(bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c767dbb1-9d4e-45ed-9c12-5f8bfdbf93d2",
   "metadata": {},
   "source": [
    "$W_b \\in R^{5\\times5}$\n",
    "$W_c \\in R^{5\\times5}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c153454d-f14b-4f6a-9794-3a500a251708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_a = nn.Linear(5,1,bias=False).weight\n",
    "W_b = nn.Linear(5,5,bias=False).weight\n",
    "W_c = nn.Linear(5,5,bias=False).weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "05d33564-d51b-4ea5-b921-f844ca7863df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.matmul(W_b,s_t1)\n",
    "b = torch.matmul(W_c,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8fb55659-dffb-4785-b741-e24734d3892c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = torch.matmul(W_a,nn.Tanh()(a+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "29b1e194-a036-4964-93db-38ad6a6346ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "att = nn.Softmax(dim=1)(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2c451784-0c3e-481c-a6bb-5a2aaf701f12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape , att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "15bc5df7-c998-457a-88a1-09c3beb49d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = att@H.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6bece02a-78c4-461a-8dfc-94f315c16aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ee3eb-8056-47b3-81e8-701161c61922",
   "metadata": {},
   "source": [
    "$s_t = (W_a s_{t-1}+cat(context_vector, input))$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
